{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69307e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Burada kullanacağımız modeli seçiyoruz.\n",
    "model= YOLO(\"yolov8m.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f9d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(source='i.jpg',save=True,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "146e632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aeca2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55f478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('i.jpg')\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = model(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0dbeb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " keys: ['boxes']\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " orig_img: array([[[ 81,  67,  67],\n",
       "         [ 84,  70,  70],\n",
       "         [ 79,  67,  69],\n",
       "         ...,\n",
       "         [ 93,  60,  71],\n",
       "         [ 93,  63,  73],\n",
       "         [ 96,  66,  78]],\n",
       " \n",
       "        [[ 79,  65,  65],\n",
       "         [ 86,  72,  72],\n",
       "         [ 90,  75,  78],\n",
       "         ...,\n",
       "         [ 94,  61,  72],\n",
       "         [ 98,  66,  77],\n",
       "         [103,  73,  83]],\n",
       " \n",
       "        [[ 98,  82,  83],\n",
       "         [ 99,  85,  85],\n",
       "         [ 99,  84,  87],\n",
       "         ...,\n",
       "         [ 96,  63,  72],\n",
       "         [102,  71,  79],\n",
       "         [108,  78,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 98,  83, 116],\n",
       "         [ 98,  83, 116],\n",
       "         [ 98,  83, 116],\n",
       "         ...,\n",
       "         [172, 154, 150],\n",
       "         [198, 180, 176],\n",
       "         [200, 182, 178]],\n",
       " \n",
       "        [[ 98,  83, 116],\n",
       "         [ 97,  82, 115],\n",
       "         [ 97,  82, 115],\n",
       "         ...,\n",
       "         [188, 170, 166],\n",
       "         [217, 199, 195],\n",
       "         [209, 191, 187]],\n",
       " \n",
       "        [[ 95,  82, 112],\n",
       "         [ 95,  82, 112],\n",
       "         [ 95,  82, 112],\n",
       "         ...,\n",
       "         [156, 137, 133],\n",
       "         [179, 160, 156],\n",
       "         [175, 156, 152]]], dtype=uint8)\n",
       " orig_shape: (669, 1879)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 6.021261215209961, 'inference': 141.58320426940918, 'postprocess': 3.988981246948242}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b288f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "boxes: tensor([[4.2180e+02, 1.6748e+02, 5.9856e+02, 5.5813e+02, 9.1224e-01, 0.0000e+00],\n",
       "        [9.6894e+02, 2.3017e+02, 1.1085e+03, 3.4269e+02, 9.0219e-01, 2.0000e+00],\n",
       "        [5.3915e+02, 2.0540e+02, 8.5619e+02, 4.0182e+02, 8.9323e-01, 2.0000e+00],\n",
       "        [7.8536e+02, 2.0792e+02, 1.0065e+03, 3.6595e+02, 8.9197e-01, 2.0000e+00],\n",
       "        [2.9944e+02, 1.6434e+02, 4.0117e+02, 5.6260e+02, 8.8522e-01, 0.0000e+00],\n",
       "        [1.6156e+03, 1.6523e+02, 1.7264e+03, 4.2277e+02, 8.8445e-01, 0.0000e+00],\n",
       "        [1.0401e+03, 2.2109e+02, 1.1816e+03, 3.2841e+02, 8.0585e-01, 2.0000e+00],\n",
       "        [1.7834e+03, 2.6974e+02, 1.8781e+03, 4.5478e+02, 7.2458e-01, 1.0000e+00],\n",
       "        [1.3819e+03, 2.7225e+02, 1.4702e+03, 3.8465e+02, 7.2282e-01, 1.0000e+00],\n",
       "        [1.1518e+03, 2.3451e+02, 1.2115e+03, 3.1544e+02, 6.0511e-01, 2.0000e+00],\n",
       "        [2.7217e+02, 2.0560e+02, 3.2092e+02, 3.5128e+02, 6.0273e-01, 0.0000e+00],\n",
       "        [1.2022e+03, 2.3604e+02, 1.2608e+03, 3.0445e+02, 5.6617e-01, 2.0000e+00],\n",
       "        [1.3605e+03, 2.2355e+02, 1.4246e+03, 2.8836e+02, 5.0980e-01, 2.0000e+00],\n",
       "        [1.2399e+03, 2.3716e+02, 1.2751e+03, 3.0039e+02, 4.0967e-01, 2.0000e+00],\n",
       "        [1.7210e+03, 2.7864e+02, 1.7985e+03, 3.9843e+02, 3.6775e-01, 1.0000e+00],\n",
       "        [8.4341e+02, 3.1610e+02, 8.9119e+02, 3.7607e+02, 3.5446e-01, 1.0000e+00],\n",
       "        [5.6052e-02, 3.3492e+02, 2.4180e+01, 4.6023e+02, 2.6422e-01, 1.0000e+01],\n",
       "        [1.1897e+03, 2.3451e+02, 1.2292e+03, 3.0832e+02, 2.5678e-01, 2.0000e+00]], device='cuda:0')\n",
       "cls: tensor([ 0.,  2.,  2.,  2.,  0.,  0.,  2.,  1.,  1.,  2.,  0.,  2.,  2.,  2.,  1.,  1., 10.,  2.], device='cuda:0')\n",
       "conf: tensor([0.9122, 0.9022, 0.8932, 0.8920, 0.8852, 0.8844, 0.8059, 0.7246, 0.7228, 0.6051, 0.6027, 0.5662, 0.5098, 0.4097, 0.3678, 0.3545, 0.2642, 0.2568], device='cuda:0')\n",
       "data: tensor([[4.2180e+02, 1.6748e+02, 5.9856e+02, 5.5813e+02, 9.1224e-01, 0.0000e+00],\n",
       "        [9.6894e+02, 2.3017e+02, 1.1085e+03, 3.4269e+02, 9.0219e-01, 2.0000e+00],\n",
       "        [5.3915e+02, 2.0540e+02, 8.5619e+02, 4.0182e+02, 8.9323e-01, 2.0000e+00],\n",
       "        [7.8536e+02, 2.0792e+02, 1.0065e+03, 3.6595e+02, 8.9197e-01, 2.0000e+00],\n",
       "        [2.9944e+02, 1.6434e+02, 4.0117e+02, 5.6260e+02, 8.8522e-01, 0.0000e+00],\n",
       "        [1.6156e+03, 1.6523e+02, 1.7264e+03, 4.2277e+02, 8.8445e-01, 0.0000e+00],\n",
       "        [1.0401e+03, 2.2109e+02, 1.1816e+03, 3.2841e+02, 8.0585e-01, 2.0000e+00],\n",
       "        [1.7834e+03, 2.6974e+02, 1.8781e+03, 4.5478e+02, 7.2458e-01, 1.0000e+00],\n",
       "        [1.3819e+03, 2.7225e+02, 1.4702e+03, 3.8465e+02, 7.2282e-01, 1.0000e+00],\n",
       "        [1.1518e+03, 2.3451e+02, 1.2115e+03, 3.1544e+02, 6.0511e-01, 2.0000e+00],\n",
       "        [2.7217e+02, 2.0560e+02, 3.2092e+02, 3.5128e+02, 6.0273e-01, 0.0000e+00],\n",
       "        [1.2022e+03, 2.3604e+02, 1.2608e+03, 3.0445e+02, 5.6617e-01, 2.0000e+00],\n",
       "        [1.3605e+03, 2.2355e+02, 1.4246e+03, 2.8836e+02, 5.0980e-01, 2.0000e+00],\n",
       "        [1.2399e+03, 2.3716e+02, 1.2751e+03, 3.0039e+02, 4.0967e-01, 2.0000e+00],\n",
       "        [1.7210e+03, 2.7864e+02, 1.7985e+03, 3.9843e+02, 3.6775e-01, 1.0000e+00],\n",
       "        [8.4341e+02, 3.1610e+02, 8.9119e+02, 3.7607e+02, 3.5446e-01, 1.0000e+00],\n",
       "        [5.6052e-02, 3.3492e+02, 2.4180e+01, 4.6023e+02, 2.6422e-01, 1.0000e+01],\n",
       "        [1.1897e+03, 2.3451e+02, 1.2292e+03, 3.0832e+02, 2.5678e-01, 2.0000e+00]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (669, 1879)\n",
       "shape: torch.Size([18, 6])\n",
       "xywh: tensor([[ 510.1815,  362.8061,  176.7537,  390.6535],\n",
       "        [1038.7124,  286.4309,  139.5543,  112.5231],\n",
       "        [ 697.6708,  303.6074,  317.0454,  196.4215],\n",
       "        [ 895.9242,  286.9358,  221.1276,  158.0268],\n",
       "        [ 350.3053,  363.4696,  101.7281,  398.2690],\n",
       "        [1671.0039,  293.9956,  110.8496,  257.5396],\n",
       "        [1110.8423,  274.7538,  141.5508,  107.3203],\n",
       "        [1830.7236,  362.2607,   94.6638,  185.0382],\n",
       "        [1426.0583,  328.4492,   88.3434,  112.3971],\n",
       "        [1181.6460,  274.9712,   59.7734,   80.9306],\n",
       "        [ 296.5433,  278.4407,   48.7435,  145.6755],\n",
       "        [1231.4773,  270.2425,   58.6390,   68.4126],\n",
       "        [1392.5511,  255.9565,   64.0796,   64.8066],\n",
       "        [1257.4790,  268.7766,   35.1920,   63.2285],\n",
       "        [1759.7189,  338.5363,   77.4749,  119.7875],\n",
       "        [ 867.2994,  346.0848,   47.7719,   59.9614],\n",
       "        [  12.1182,  397.5769,   24.1243,  125.3052],\n",
       "        [1209.4442,  271.4141,   39.5881,   73.8143]], device='cuda:0')\n",
       "xywhn: tensor([[0.2715, 0.5423, 0.0941, 0.5839],\n",
       "        [0.5528, 0.4281, 0.0743, 0.1682],\n",
       "        [0.3713, 0.4538, 0.1687, 0.2936],\n",
       "        [0.4768, 0.4289, 0.1177, 0.2362],\n",
       "        [0.1864, 0.5433, 0.0541, 0.5953],\n",
       "        [0.8893, 0.4395, 0.0590, 0.3850],\n",
       "        [0.5912, 0.4107, 0.0753, 0.1604],\n",
       "        [0.9743, 0.5415, 0.0504, 0.2766],\n",
       "        [0.7589, 0.4910, 0.0470, 0.1680],\n",
       "        [0.6289, 0.4110, 0.0318, 0.1210],\n",
       "        [0.1578, 0.4162, 0.0259, 0.2178],\n",
       "        [0.6554, 0.4039, 0.0312, 0.1023],\n",
       "        [0.7411, 0.3826, 0.0341, 0.0969],\n",
       "        [0.6692, 0.4018, 0.0187, 0.0945],\n",
       "        [0.9365, 0.5060, 0.0412, 0.1791],\n",
       "        [0.4616, 0.5173, 0.0254, 0.0896],\n",
       "        [0.0064, 0.5943, 0.0128, 0.1873],\n",
       "        [0.6437, 0.4057, 0.0211, 0.1103]], device='cuda:0')\n",
       "xyxy: tensor([[4.2180e+02, 1.6748e+02, 5.9856e+02, 5.5813e+02],\n",
       "        [9.6894e+02, 2.3017e+02, 1.1085e+03, 3.4269e+02],\n",
       "        [5.3915e+02, 2.0540e+02, 8.5619e+02, 4.0182e+02],\n",
       "        [7.8536e+02, 2.0792e+02, 1.0065e+03, 3.6595e+02],\n",
       "        [2.9944e+02, 1.6434e+02, 4.0117e+02, 5.6260e+02],\n",
       "        [1.6156e+03, 1.6523e+02, 1.7264e+03, 4.2277e+02],\n",
       "        [1.0401e+03, 2.2109e+02, 1.1816e+03, 3.2841e+02],\n",
       "        [1.7834e+03, 2.6974e+02, 1.8781e+03, 4.5478e+02],\n",
       "        [1.3819e+03, 2.7225e+02, 1.4702e+03, 3.8465e+02],\n",
       "        [1.1518e+03, 2.3451e+02, 1.2115e+03, 3.1544e+02],\n",
       "        [2.7217e+02, 2.0560e+02, 3.2092e+02, 3.5128e+02],\n",
       "        [1.2022e+03, 2.3604e+02, 1.2608e+03, 3.0445e+02],\n",
       "        [1.3605e+03, 2.2355e+02, 1.4246e+03, 2.8836e+02],\n",
       "        [1.2399e+03, 2.3716e+02, 1.2751e+03, 3.0039e+02],\n",
       "        [1.7210e+03, 2.7864e+02, 1.7985e+03, 3.9843e+02],\n",
       "        [8.4341e+02, 3.1610e+02, 8.9119e+02, 3.7607e+02],\n",
       "        [5.6052e-02, 3.3492e+02, 2.4180e+01, 4.6023e+02],\n",
       "        [1.1897e+03, 2.3451e+02, 1.2292e+03, 3.0832e+02]], device='cuda:0')\n",
       "xyxyn: tensor([[2.2448e-01, 2.5034e-01, 3.1855e-01, 8.3428e-01],\n",
       "        [5.1567e-01, 3.4405e-01, 5.8994e-01, 5.1225e-01],\n",
       "        [2.8693e-01, 3.0702e-01, 4.5566e-01, 6.0063e-01],\n",
       "        [4.1797e-01, 3.1080e-01, 5.3565e-01, 5.4701e-01],\n",
       "        [1.5936e-01, 2.4564e-01, 2.1350e-01, 8.4096e-01],\n",
       "        [8.5981e-01, 2.4697e-01, 9.1880e-01, 6.3194e-01],\n",
       "        [5.5352e-01, 3.3048e-01, 6.2885e-01, 4.9090e-01],\n",
       "        [9.4912e-01, 4.0320e-01, 9.9950e-01, 6.7979e-01],\n",
       "        [7.3544e-01, 4.0695e-01, 7.8245e-01, 5.7496e-01],\n",
       "        [6.1296e-01, 3.5053e-01, 6.4478e-01, 4.7150e-01],\n",
       "        [1.4485e-01, 3.0733e-01, 1.7079e-01, 5.2508e-01],\n",
       "        [6.3979e-01, 3.5282e-01, 6.7099e-01, 4.5508e-01],\n",
       "        [7.2406e-01, 3.3416e-01, 7.5816e-01, 4.3103e-01],\n",
       "        [6.5986e-01, 3.5450e-01, 6.7859e-01, 4.4901e-01],\n",
       "        [9.1590e-01, 4.1651e-01, 9.5713e-01, 5.9556e-01],\n",
       "        [4.4886e-01, 4.7250e-01, 4.7429e-01, 5.6213e-01],\n",
       "        [2.9831e-05, 5.0063e-01, 1.2869e-02, 6.8794e-01],\n",
       "        [6.3313e-01, 3.5053e-01, 6.5420e-01, 4.6087e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3e4b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2180e+02, 1.6748e+02, 5.9856e+02, 5.5813e+02],\n",
       "        [9.6894e+02, 2.3017e+02, 1.1085e+03, 3.4269e+02],\n",
       "        [5.3915e+02, 2.0540e+02, 8.5619e+02, 4.0182e+02],\n",
       "        [7.8536e+02, 2.0792e+02, 1.0065e+03, 3.6595e+02],\n",
       "        [2.9944e+02, 1.6434e+02, 4.0117e+02, 5.6260e+02],\n",
       "        [1.6156e+03, 1.6523e+02, 1.7264e+03, 4.2277e+02],\n",
       "        [1.0401e+03, 2.2109e+02, 1.1816e+03, 3.2841e+02],\n",
       "        [1.7834e+03, 2.6974e+02, 1.8781e+03, 4.5478e+02],\n",
       "        [1.3819e+03, 2.7225e+02, 1.4702e+03, 3.8465e+02],\n",
       "        [1.1518e+03, 2.3451e+02, 1.2115e+03, 3.1544e+02],\n",
       "        [2.7217e+02, 2.0560e+02, 3.2092e+02, 3.5128e+02],\n",
       "        [1.2022e+03, 2.3604e+02, 1.2608e+03, 3.0445e+02],\n",
       "        [1.3605e+03, 2.2355e+02, 1.4246e+03, 2.8836e+02],\n",
       "        [1.2399e+03, 2.3716e+02, 1.2751e+03, 3.0039e+02],\n",
       "        [1.7210e+03, 2.7864e+02, 1.7985e+03, 3.9843e+02],\n",
       "        [8.4341e+02, 3.1610e+02, 8.9119e+02, 3.7607e+02],\n",
       "        [5.6052e-02, 3.3492e+02, 2.4180e+01, 4.6023e+02],\n",
       "        [1.1897e+03, 2.3451e+02, 1.2292e+03, 3.0832e+02]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c403b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1,x2,y2=results[0].boxes.xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd813d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(421.8047, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee5515",
   "metadata": {},
   "source": [
    "# Resimde Nesne Tespiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06e43a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img=cv2.imread('i2.jpg')\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = model(rgb_img) \n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "for i in range(len(results[0].boxes)):\n",
    "    x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "    score=results[0].boxes.conf[i]\n",
    "    label=results[0].boxes.cls[i]\n",
    "    x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)\n",
    "    name=labels[label]\n",
    "    if score<0.2:\n",
    "        continue\n",
    "\n",
    "\n",
    "    cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    text= name+' '+str(format(score, '.2f'))\n",
    "    cv2.putText(img, text,(x1, y1-10), font, 1.2, (255,0,255), 2)\n",
    "    \n",
    "    \n",
    "cv2.imshow(\"kamera\",img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dafe10",
   "metadata": {},
   "source": [
    "# Spesifik Bir Sınıfı Gösterme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604a5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('i2.jpg')\n",
    "rgb_img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "results = model(rgb_img) \n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "for i in range(len(results[0].boxes)):\n",
    "    x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "    score=results[0].boxes.conf[i]\n",
    "    label=results[0].boxes.cls[i]\n",
    "    x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)\n",
    "    name=labels[label]\n",
    "    if score<0.5 or name!='person':\n",
    "        continue\n",
    "\n",
    "\n",
    "    cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    text= name+' '+str(format(score, '.2f'))\n",
    "    cv2.putText(img, text,(x1, y1-10), font, 1.2, (102,0,153), 2)\n",
    "cv2.imshow(\"kamera\",img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2ace2",
   "metadata": {},
   "source": [
    "# Videoda Nesne Tespiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f67d1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kamera= cv2.VideoCapture('video.mp4')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "    \n",
    "    ret,kare=kamera.read()\n",
    "    \n",
    "    imgs=cv2.cvtColor(kare,cv2.COLOR_BGR2RGB)\n",
    "    results = model(imgs,verbose=False) \n",
    "    \n",
    "    for i in range(len(results[0].boxes)):\n",
    "        x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "        score=results[0].boxes.conf[i]\n",
    "        label=results[0].boxes.cls[i]\n",
    "        x1,y1,x2,y2,score,label=int(x1),int(y1),int(x2),int(y2),float(score),int(label)\n",
    "        name=labels[label]\n",
    "        if score<0.5:\n",
    "            continue\n",
    "\n",
    "\n",
    "        cv2.rectangle(kare,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        text= name+' '+str(format(score, '.2f'))\n",
    "        cv2.putText(kare, text,(x1, y1-10), font, 1.2, (255,0,255), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"kamera\",kare)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "kamera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6df6f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model= YOLO(\"yolov8n.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae041458",
   "metadata": {},
   "source": [
    "# Nesne Takibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fef5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model= YOLO(\"yolov8l.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01a2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kamera= cv2.VideoCapture('video2.mp4')\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "\n",
    "    \n",
    "    ret,kare=kamera.read()\n",
    "    \n",
    "    imgs=cv2.cvtColor(kare,cv2.COLOR_BGR2RGB)\n",
    "    results = model.track(imgs,persist=True,verbose=False) \n",
    "    \n",
    "    for i in range(len(results[0].boxes)):\n",
    "        x1,y1,x2,y2=results[0].boxes.xyxy[i]\n",
    "        score=results[0].boxes.conf[i]\n",
    "        label=results[0].boxes.cls[i]\n",
    "        ids=results[0].boxes.id[i]\n",
    "        x1,y1,x2,y2,score,label,ids=int(x1),int(y1),int(x2),int(y2),float(score),int(label),int(ids)\n",
    "        \n",
    "        name=labels[label]\n",
    "        if score<0.1:\n",
    "            continue\n",
    "\n",
    "\n",
    "        cv2.rectangle(kare,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        text= name+' '+str(ids)+' '+str(format(score, '.2f'))\n",
    "        cv2.putText(kare, text,(x1, y1-10), font, 1.2, (102,0,153), 2)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"kamera\",kare)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "kamera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa68ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387df1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0dbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593c757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
